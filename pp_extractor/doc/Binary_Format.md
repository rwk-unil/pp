# Binary format description

For faster access to individual heterozygous variants a binary format is used instead of BCF. The ideas are very similar to the XSI file format https://github.com/rwk-unil/xSqueezeIt

The expected input file is a BCF file phased with SHAPEIT5 https://github.com/odelaneau/shapeit5 with **PP** values (Phasing Probability), a score given by the phasing software (here SHAPEIT5). For example : 0.5 (50%) being equivalent to a coin toss, 0.99 (99%) the software is very sure of its call, "missing" (no PP given), is for common variants phased with high certainty.

First, the original BCF is split and only the variant sites are kept, this can be done with the following BCFTools command :

```shell
bcftools view -G -Ob "${BCF_FILENAME}" -o "${BCF_FILENAME}_vars.bcf"
```

This way we can load the variant site info rapidly if needed.

Second, the original BCF is parsed and het variants with PP < 0.99 (Phasing Probability) are extracted for each sample alongside a number of surrounding het variants (e.g., 2 before, 2 after) if there are any. All those het variants are stored in the binary file.

```shell
pp_extract -f "${BCF_FILENAME}" -o "${BCF_FILENAME}_hets.bin"
```

Keeping variant site information in BCF and storing the per sample variant info in a specialized binary format is the main idea behind XSI. The binary format here is lossy because it doesn't store all variant info, for example none of the hom variant info is kept, also het variants with no or high PP (> 0.99) that don't surround low PP het variants are not stored. This is by design because only the het info required for rephasing is kept in the binary file.

## Binary file format

The binary file is generated by the `pp_extract` tool. **The input BCF file must have PP field otherwise the binary file will hold no variants!**.

### Binary file contents

| **Field**              | **Type**    | **Value**                                                                        |
|------------------------|-------------|----------------------------------------------------------------------------------|
| Endianness             | uint32_t    | 0xaabbccdd                                                                       |
| # Samples              | uint32_t    | 0-UINT32_MAX                                                                     |
| Offset table           | uint64_t[]  | Offsets of sample data blocks wrt start of file, one offset per sample           |
| Per sample data blocks | SampleBlock | Per sample data blocks (see below)                                               |

### Sample block data

This is the data type for the "Per sample data block" in the binary file format above.

| **Field**         | **Type**  | **Value**                                 |
|-------------------|-----------|-------------------------------------------|
| Sanity Check Code | uint32_t  | 0xd00dc0de (aka "mark")                   |
| ID                | uint32_t  | nth sample in original BCF file (0 based) |
| # Het info data   | uint32_t  | Number of het info data for sample        |
| Het info          | HetInfo[] | Heterozygous variant info                 |

### Het Info

This is the data type for the "Heterozygous variant info" in the sample block format above.

| **Field** | **Type** | **Value**                                                |
|-----------|----------|----------------------------------------------------------|
| VCF Line  | uint32_t | Corresponding VCF line in the original VCF/BCF (0 based) |
| allele 0  | uint32_t | In BCF format (use `bcf_gt_allele()` to extract allele)  |
| allele 1  | uint32_t | In BCF format (e.g., will have bit 0 set if phased)      |
| PP        | float    | PP value, NaN if missing in BCF                          |

## Reasoning behind file format

The file format is extremely simple and has no compression at all. However, it allows for extremely quick access and loading. This format is sparse and only stores heterozygous variants under specific conditions (see top) so size is not a problem. E.g., on UKBiobank 150k samples the BCF for CHR20 is about 30GB, the binary file will be less than 1.5GB (uncompressed).

The simplicity of use and rapidity of access make it a good choice. The file can be memory mapped and accessed directly as a table, it can also be modified in-place. The reason why `uint32_t` aka `int` are used for the alleles is because the 1-to-1 mapping with the BCF file format, this allows to directly copy the alleles from one to another (with "phasing" and "missing" information as in BCF).

### Easy improvements if file size becomes an issue

* Compress the file (e.g., gzip, zstd, 7z, ...).
* Encode alleles on `uint8_t`, very easy to do and will save most space, however it will require some code to encode from and to BCF.
* Remove "Sanity Check Code", this is only useful to check if the file is not corrupt and offsets refer to a sane location.

For the moment none of the workloads caused file size issues (even whole chromosomes with 200k samples).

### QoL improvements

* Add the list of sample IDs (strings) as in the original VCF/BCF to be able to double check that the ID of indeed for the right sample (this is however not necessary when used in the given pipeline).